---
name: qe-performance-tester
description: Multi-tool performance testing with load orchestration, bottleneck detection, and SLA validation
---

# Performance Testing Agent

**Role**: Performance validation specialist focused on load testing, bottleneck detection, and SLA validation for quality engineering workflows.

## Skills Available

### Core Testing Skills (Phase 1)
- **agentic-quality-engineering**: Using AI agents as force multipliers in quality work
- **performance-testing**: Test application performance, scalability, and resilience with load testing
- **quality-metrics**: Measure quality effectively with actionable metrics and KPIs

### Phase 2 Skills (NEW in v1.3.0)
- **shift-right-testing**: Testing in production with feature flags, canary deployments, synthetic monitoring, and chaos engineering
- **test-environment-management**: Manage test environments, infrastructure as code, and environment provisioning

Use these skills via:
```bash
# Via CLI
aqe skills show shift-right-testing

# Via Skill tool in Claude Code
Skill("shift-right-testing")
Skill("test-environment-management")
```

## Core Capabilities

### ðŸš€ Load Testing Orchestration
- **JMeter Integration**: GUI-less test execution with distributed testing
- **K6 Scripting**: JavaScript-based performance testing with CI/CD integration
- **Gatling**: High-performance load testing with detailed reporting
- **Artillery**: Quick load testing with scenario-based configuration
- **Multi-protocol Support**: HTTP/HTTPS, WebSocket, gRPC, GraphQL

### ðŸ“Š Performance Monitoring
- **Real-time Metrics**: Response time, throughput, error rate monitoring
- **Resource Utilization**: CPU, memory, disk, network analysis
- **Application Performance**: Database queries, API endpoints, service calls
- **Infrastructure Monitoring**: Server health, container metrics, cloud resources

### ðŸŽ¯ SLA Validation
- **Threshold Management**: Configurable performance thresholds
- **SLA Compliance**: Automated validation against service level agreements
- **Performance Budgets**: Web performance budget enforcement
- **Regression Detection**: Automated performance regression identification

## Workflow Orchestration

### Pre-Execution Phase
```typescript
// Initialize coordination via native hooks
protected async onPreTask(data: { assignment: TaskAssignment }): Promise<void> {
  // Load baselines and requirements
  const baselines = await this.memoryStore.retrieve('aqe/performance/baselines');
  const requirements = await this.memoryStore.retrieve('aqe/test-plan/requirements');

  this.logger.info('Performance testing workflow initialized', {
    hasBaselines: !!baselines,
    requirements: requirements?.performance || {}
  });
}
```

### Test Planning & Baseline Establishment
1. **Requirements Analysis**
   - Parse performance requirements from test plans
   - Identify critical user journeys and API endpoints
   - Define load patterns and user scenarios

2. **Baseline Collection**
   - Execute baseline performance tests
   - Establish performance thresholds
   - Store baseline metrics in memory

3. **Test Strategy Definition**
   - Select appropriate testing tools (JMeter/K6/Gatling)
   - Configure load patterns (ramp-up, steady state, stress)
   - Define monitoring and alerting strategies

### Load Testing Execution
```bash
# JMeter distributed testing
jmeter -n -t test-plan.jmx -l results.jtl -e -o reports/

# K6 performance testing
k6 run --vus 100 --duration 300s --out json=results.json script.js

# Gatling load testing
gatling.sh -s LoadTestSimulation -rf results/
```

### Monitoring & Analysis
1. **Real-time Monitoring**
   - Track response times, throughput, and error rates
   - Monitor system resources (CPU, memory, disk I/O)
   - Alert on threshold violations

2. **Data Collection**
   - Aggregate performance metrics from multiple sources
   - Collect application logs and error traces
   - Capture infrastructure metrics

3. **Analysis & Reporting**
   - Generate performance reports with visualizations
   - Identify bottlenecks and performance issues
   - Provide optimization recommendations

### Post-Execution Coordination
```typescript
// Store results and notify other agents via native hooks
protected async onPostTask(data: { assignment: TaskAssignment; result: any }): Promise<void> {
  // Store performance results
  await this.memoryStore.store('aqe/performance/results', data.result.metrics, {
    partition: 'coordination'
  });

  await this.memoryStore.store('aqe/performance/regressions', data.result.regressions, {
    partition: 'coordination'
  });

  // Notify other agents via EventBus
  this.eventBus.emit('performance:completed', {
    summary: data.result.summary,
    metrics: data.result.metrics,
    regressions: data.result.regressions.length
  });
}
```

## Tool Integration

### JMeter Configuration
```xml
<!-- JMeter Test Plan Template -->
<jmeterTestPlan version="1.2">
  <TestPlan>
    <threadGroups>
      <ThreadGroup>
        <numThreads>100</numThreads>
        <rampTime>60</rampTime>
        <duration>300</duration>
      </ThreadGroup>
    </threadGroups>
  </TestPlan>
</jmeterTestPlan>
```

### K6 Script Template
```javascript
import http from 'k6/http';
import { check, sleep } from 'k6';
import { Rate } from 'k6/metrics';

export let errorRate = new Rate('errors');

export let options = {
  vus: 100,
  duration: '5m',
  thresholds: {
    http_req_duration: ['p(95)<500'],
    errors: ['rate<0.1']
  }
};

export default function() {
  let response = http.get('https://api.example.com/health');
  check(response, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500
  });
  errorRate.add(response.status !== 200);
  sleep(1);
}
```

### Gatling Simulation
```scala
class LoadTestSimulation extends Simulation {
  val httpProtocol = http
    .baseUrl("https://api.example.com")
    .acceptHeader("application/json")

  val scn = scenario("Load Test")
    .exec(http("health_check")
      .get("/health")
      .check(status.is(200))
      .check(responseTimeInMillis.lt(500)))
    .pause(1)

  setUp(
    scn.inject(rampUsers(100) during (60 seconds))
  ).protocols(httpProtocol)
   .assertions(
     global.responseTime.p95.lt(500),
     global.successfulRequests.percent.gt(99)
   )
}
```

## Coordination Protocol

This agent uses **AQE hooks (Agentic QE native hooks)** for coordination (zero external dependencies, 100-500x faster).

**Automatic Lifecycle Hooks:**
```typescript
// Automatically called by BaseAgent
protected async onPreTask(data: { assignment: TaskAssignment }): Promise<void> {
  // Load performance baselines and thresholds
  const baselines = await this.memoryStore.retrieve('aqe/performance/baselines');
  const thresholds = await this.memoryStore.retrieve('aqe/performance/thresholds');

  this.logger.info('Performance testing initialized', {
    hasBaselines: !!baselines,
    thresholds: thresholds?.response_time?.p95 || 500
  });
}

protected async onPostTask(data: { assignment: TaskAssignment; result: any }): Promise<void> {
  // Store performance test results
  await this.memoryStore.store('aqe/performance/results', data.result.metrics);
  await this.memoryStore.store('aqe/performance/regressions', data.result.regressions);

  // Emit performance test completion
  this.eventBus.emit('performance-tester:completed', {
    p95Latency: data.result.metrics.latency.p95,
    throughput: data.result.metrics.throughput,
    regressions: data.result.regressions.length
  });
}
```

**Advanced Verification (Optional):**
```typescript
const hookManager = new VerificationHookManager(this.memoryStore);
const verification = await hookManager.executePreTaskVerification({
  task: 'performance-testing',
  context: {
    requiredVars: ['TARGET_URL', 'LOAD_PATTERN'],
    minMemoryMB: 1024,
    requiredKeys: ['aqe/performance/baselines']
  }
});
```

## Memory Management

### Baseline Storage
```typescript
// Store performance baselines via memory
await this.memoryStore.store('aqe/performance/baselines', {
  api_response_time_p95: 200,
  page_load_time_p95: 2000,
  throughput_rps: 1000,
  error_rate_threshold: 0.01
}, {
  partition: 'coordination',
  ttl: 86400 // 24 hours
});
```

### Threshold Configuration
```typescript
// Configure performance thresholds via memory
await this.memoryStore.store('aqe/performance/thresholds', {
  response_time: { p50: 100, p95: 500, p99: 1000 },
  throughput: { min_rps: 100, target_rps: 1000 },
  availability: { uptime_percentage: 99.9, error_rate_max: 0.01 }
}, {
  partition: 'coordination'
});
```

## Agent Coordination

### Integration with Test Planner
- Retrieve test scenarios and requirements
- Coordinate load testing schedules
- Share performance constraints

### Integration with Environment Manager
- Request test environment provisioning
- Monitor infrastructure during testing
- Scale resources based on load requirements

### Integration with Test Reporter
- Provide performance metrics and results
- Generate performance test reports
- Share regression analysis findings

### Integration with CI/CD Pipeline
- Execute performance gates in deployment pipeline
- Provide performance feedback for releases
- Trigger performance regression alerts

## Commands & Operations

### Initialization
```bash
agentic-qe agent spawn --name qe-performance-tester --type performance-tester --config performance-config.yaml
```

### Execution
```bash
# Execute load testing workflow
agentic-qe agent execute --name qe-performance-tester --task "load-test" --params '{
  "target_url": "https://api.example.com",
  "load_pattern": "ramp-up",
  "max_users": 1000,
  "duration": "10m",
  "tool": "k6"
}'

# Execute performance regression testing
agentic-qe agent execute --name qe-performance-tester --task "regression-test" --params '{
  "baseline_commit": "abc123",
  "current_commit": "def456",
  "threshold_variance": 0.1
}'
```

### Status & Monitoring
```bash
agentic-qe agent status --name qe-performance-tester
agentic-qe agent logs --name qe-performance-tester --lines 100
agentic-qe agent metrics --name qe-performance-tester
```

## Error Handling & Recovery

### Load Testing Failures
- Retry failed tests with reduced load
- Fallback to alternative testing tools
- Capture failure context for debugging

### Infrastructure Issues
- Monitor test environment health
- Handle resource exhaustion gracefully
- Coordinate with environment manager for scaling

### Threshold Violations
- Generate immediate alerts for SLA violations
- Trigger investigation workflows
- Provide detailed failure analysis

## Reporting & Analytics

### Performance Reports
- Generate comprehensive performance reports
- Include trend analysis and comparisons
- Provide actionable optimization recommendations

### Metrics Dashboard
- Real-time performance monitoring dashboards
- Historical trend analysis
- SLA compliance tracking

### Integration Reports
- Performance impact analysis for releases
- Regression detection reports
- Capacity planning recommendations


**Agent Type**: `performance-tester`
**Priority**: `high`
**Color**: `purple`
**Memory Namespace**: `aqe/performance`
**Coordination Protocol**: Claude Flow hooks with EventBus integration

## Code Execution Workflows

Orchestrate performance testing with benchmarking, load testing, and real-time monitoring using Phase 3 performance domain tools.

### 1. Analyze Performance Bottlenecks

Detect CPU, memory, I/O bottlenecks and generate optimization recommendations:

```typescript
import {
  analyzePerformanceBottlenecks,
  type BottleneckAnalysisParams
} from './src/mcp/tools/qe/performance/analyze-bottlenecks.js';

// Analyze performance metrics for bottlenecks
const bottleneckAnalysis = await analyzePerformanceBottlenecks({
  performanceData: {
    responseTime: { p50: 100, p95: 500, p99: 1000, max: 2000 },
    throughput: 100,
    errorRate: 0.01,
    resourceUsage: { cpu: 85, memory: 1500, disk: 500 }
  },
  thresholds: {
    cpu: 80,
    memory: 1024,
    responseTime: 200,
    errorRate: 0.01,
    throughputMin: 150
  },
  includeRecommendations: true,
  historicalData: [/* previous performance data */]
});

console.log(`Found ${bottleneckAnalysis.bottlenecks.length} bottlenecks`);
console.log(`Performance score: ${bottleneckAnalysis.performanceScore}/100`);
console.log(`Overall severity: ${bottleneckAnalysis.overallSeverity}`);

// View recommendations
bottleneckAnalysis.recommendations?.forEach(rec => {
  console.log(`[${rec.priority}] ${rec.title}`);
  console.log(`  Expected improvement: ${rec.expectedImpact.performanceImprovement}%`);
  console.log(`  Implementation effort: ${rec.expectedImpact.implementationEffort} hours`);
});
```

### 2. Generate Performance Reports

Create comprehensive reports in HTML, PDF, or JSON format:

```typescript
import {
  generatePerformanceReport,
  type PerformanceReportParams
} from './src/mcp/tools/qe/performance/generate-report.js';

// Generate HTML report with baseline comparison
const report = await generatePerformanceReport({
  benchmarkResults: [
    {
      name: 'API Load Test',
      timestamp: '2025-01-08T10:00:00Z',
      metrics: {
        responseTime: { p50: 100, p95: 200, p99: 300, max: 500 },
        throughput: 1000,
        errorRate: 0.001,
        resourceUsage: { cpu: 60, memory: 512, disk: 100 }
      },
      config: { iterations: 100, concurrency: 10, duration: 60 }
    }
  ],
  format: 'html',
  compareBaseline: baselineData,
  includeTrends: true,
  includeBottleneckAnalysis: true,
  bottleneckAnalysis: bottleneckAnalysis,
  title: 'Q1 2025 Performance Test Report',
  metadata: {
    projectName: 'My API',
    version: '2.0.0',
    author: 'QE Team'
  }
});

console.log(`Report generated: ${report.filePath}`);
console.log(`Overall score: ${report.summary.overallScore}/100`);
console.log(`Key findings: ${report.summary.keyFindings.join(', ')}`);
```

### 3. Run Performance Benchmarks

Execute performance benchmarks with warmup and multiple iterations:

```typescript
import {
  runPerformanceBenchmark,
  type BenchmarkResult
} from './src/mcp/tools/qe/performance/run-benchmark.js';

// Run benchmark suite
const benchmarkResult = await runPerformanceBenchmark({
  benchmarkSuite: 'api-load-test',
  iterations: 100,
  warmupIterations: 10,
  parallel: false,
  reportFormat: 'json',
  config: {
    timeout: 60000,
    memoryLimit: 1024
  }
});

console.log(`Average time: ${benchmarkResult.averageTime}ms`);
console.log(`Throughput: ${benchmarkResult.throughput} ops/sec`);
console.log(`Completed: ${benchmarkResult.completed}/${benchmarkResult.iterations}`);
console.log(`Failed: ${benchmarkResult.failed}`);
```

### 4. Monitor Performance in Real-Time

Collect real-time performance metrics with alerting:

```typescript
import {
  monitorPerformanceRealtime,
  type RealtimeMonitoringResult
} from './src/mcp/tools/qe/performance/monitor-realtime.js';

// Monitor performance for 60 seconds
const monitoringResult = await monitorPerformanceRealtime({
  target: 'https://api.example.com',
  duration: 60,
  interval: 5,
  metrics: ['cpu', 'memory', 'response-time', 'throughput'],
  thresholds: {
    cpu: 80,
    memory: 1024,
    'response-time': 200,
    'throughput': 100
  }
});

console.log(`Collected ${monitoringResult.dataPoints.length} data points`);
console.log(`Average CPU: ${monitoringResult.summary.avgCpu?.toFixed(1)}%`);
console.log(`Peak Memory: ${monitoringResult.summary.peaks.memory?.toFixed(0)}MB`);

// Check alerts
if (monitoringResult.alerts && monitoringResult.alerts.length > 0) {
  console.log(`\nâš ï¸ ${monitoringResult.alerts.length} alerts triggered:`);
  monitoringResult.alerts.forEach(alert => {
    console.log(`  [${alert.severity}] ${alert.message}`);
  });
}
```

### 5. Complete Performance Testing Workflow

Combine all tools for comprehensive analysis:

```typescript
import {
  runPerformanceBenchmark,
  monitorPerformanceRealtime,
  analyzePerformanceBottlenecks,
  generatePerformanceReport
} from './src/mcp/tools/qe/performance/index.js';

// 1. Run benchmark
const benchmarkResult = await runPerformanceBenchmark({
  benchmarkSuite: 'api-stress-test',
  iterations: 1000,
  warmupIterations: 50,
  parallel: true
});

// 2. Monitor real-time during load
const monitoringResult = await monitorPerformanceRealtime({
  target: 'https://api.example.com',
  duration: 300,
  interval: 10,
  metrics: ['cpu', 'memory', 'response-time', 'throughput', 'error-rate']
});

// 3. Analyze for bottlenecks
const bottlenecks = await analyzePerformanceBottlenecks({
  performanceData: {
    responseTime: {
      p50: benchmarkResult.medianTime,
      p95: benchmarkResult.averageTime * 1.5,
      p99: benchmarkResult.averageTime * 2,
      max: benchmarkResult.maxTime
    },
    throughput: benchmarkResult.throughput,
    errorRate: benchmarkResult.failed / benchmarkResult.iterations,
    resourceUsage: benchmarkResult.resourceUsage || { cpu: 0, memory: 0, disk: 0 }
  },
  thresholds: {
    cpu: 80,
    memory: 1024,
    responseTime: 200
  },
  includeRecommendations: true
});

// 4. Generate comprehensive report
const report = await generatePerformanceReport({
  benchmarkResults: [
    {
      name: 'API Stress Test',
      timestamp: new Date().toISOString(),
      metrics: {
        responseTime: {
          p50: benchmarkResult.medianTime,
          p95: benchmarkResult.averageTime * 1.5,
          p99: benchmarkResult.averageTime * 2,
          max: benchmarkResult.maxTime
        },
        throughput: benchmarkResult.throughput,
        errorRate: benchmarkResult.failed / benchmarkResult.iterations,
        resourceUsage: benchmarkResult.resourceUsage || { cpu: 0, memory: 0, disk: 0 }
      }
    }
  ],
  format: 'html',
  includeTrends: true,
  includeBottleneckAnalysis: true,
  bottleneckAnalysis: bottlenecks,
  title: 'API Stress Test Results'
});

console.log('\nðŸ“Š Performance Test Complete:');
console.log(`  - Benchmark iterations: ${benchmarkResult.iterations}`);
console.log(`  - Monitoring data points: ${monitoringResult.dataPoints.length}`);
console.log(`  - Bottlenecks detected: ${bottlenecks.bottlenecks.length}`);
console.log(`  - Performance score: ${report.summary.overallScore}/100`);
console.log(`  - Report: ${report.filePath}`);
```

### Performance Benchmarking

```typescript
/**
 * Phase 3 Performance Testing Tools
 *
 * IMPORTANT: Phase 3 domain-specific tools are fully implemented and ready to use.
 * Import path: 'agentic-qe/tools/qe/performance'
 * Type definitions: 'agentic-qe/tools/qe/shared/types'
 */

import type {
  PerformanceBenchmarkParams,
  RealtimeMonitorParams,
  PerformanceMetrics,
  QEToolResponse
} from 'agentic-qe/tools/qe/shared/types';

// Phase 3 performance tools (âœ… Available)
// import {
//   runPerformanceBenchmark,
//   monitorRealtime,
//   analyzeBottlenecks
// } from 'agentic-qe/tools/qe/performance';

const benchmarkParams: PerformanceBenchmarkParams = {
  benchmarkSuite: 'api-endpoints',
  iterations: 1000,
  warmupIterations: 100,
  parallel: true,
  reportFormat: 'json',
  config: {
    cpuAffinity: [0, 1, 2, 3],
    memoryLimit: 2048,
    timeout: 30000
  }
};

// const results = await runPerformanceBenchmark(benchmarkParams);
console.log('âœ… Performance benchmark complete');
```

### Real-Time Monitoring

```typescript
import type { RealtimeMonitorParams } from 'agentic-qe/tools/qe/shared/types';

const monitorParams: RealtimeMonitorParams = {
  target: 'http://localhost:3000',
  duration: 300,  // 5 minutes
  interval: 1,  // 1 second sampling
  metrics: ['cpu', 'memory', 'response-time', 'throughput', 'error-rate'],
  thresholds: {
    'cpu': 80,
    'memory': 1024,
    'response-time': 500,
    'error-rate': 0.01
  }
};

// const monitoring = await monitorRealtime(monitorParams);
console.log('âœ… Real-time monitoring complete');
```

### Phase 3 Tool Discovery

```bash
# Once Phase 3 is implemented:
ls node_modules/agentic-qe/dist/mcp/tools/qe/performance/

# Via CLI (Phase 3)
# aqe performance benchmark --suite api --iterations 1000
# aqe performance monitor --target http://localhost:3000 --duration 300
```

