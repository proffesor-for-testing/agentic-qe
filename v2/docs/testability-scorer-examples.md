# Testability Scorer - Example Usage

Complete examples demonstrating how to use the testability scorer skill in real-world scenarios.

---

## Example 1: Quick Assessment of a React App

### Scenario
You have a React todo application and want a rapid testability check.

### Commands
```bash
# Navigate to skill directory
cd .claude/skills/testability-scorer

# Run quick 5-principle assessment
./scripts/quick-check.sh https://todomvc.com/examples/react
```

### Expected Output
```
âš¡ Running Quick Testability Check (5 principles)...
   URL: https://todomvc.com/examples/react
   Estimated time: 2 minutes

Running 5 of 5 tests

  âœ“ 1. Observability Assessment (3s)
    - Console logging: Present âœ“
    - Network visibility: Good âœ“
    - State inspection: Limited âš ï¸
    Score: 68/100 (D)

  âœ— 2. Controllability Assessment (2s)
    - Direct API access: Not found âœ—
    - State manipulation: Not available âœ—
    - Test data injection: Not supported âœ—
    Score: 45/100 (F) âš ï¸

  âœ“ 3. Algorithmic Simplicity Assessment (2s)
    - Logic complexity: Low âœ“
    - Interaction patterns: Simple âœ“
    - Data flow: Clear âœ“
    Score: 82/100 (B)

  âœ— 4. Explainability Assessment (3s)
    - Documentation: Minimal âš ï¸
    - Error messages: Generic âš ï¸
    - Code comments: Sparse âš ï¸
    Score: 51/100 (F)

  âœ“ 5. Decomposability Assessment (2s)
    - Component isolation: Good âœ“
    - Module separation: Clear âœ“
    - Test boundaries: Defined âœ“
    Score: 74/100 (C)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š QUICK TESTABILITY SCORE: 64/100 (D)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”´ Critical Issues:
  â€¢ Controllability: 45/100 - Add test APIs
  â€¢ Explainability: 51/100 - Improve documentation

ğŸ’¡ Quick Wins (+23 points potential):
  1. Add window.testAPI for state control (+15)
  2. Add JSDoc comments (+8)

âœ… Quick check complete!

For comprehensive 10-principle analysis:
   ./scripts/run-assessment.sh https://todomvc.com/examples/react
```

---

## Example 2: Full Assessment with Report

### Scenario
Comprehensive testability analysis with detailed HTML report.

### Commands
```bash
# Run full 10-principle assessment
./scripts/run-assessment.sh https://www.saucedemo.com chromium
```

### Expected Output
```
ğŸ” Running Full Testability Assessment...
   URL: https://www.saucedemo.com
   Browser: chromium

ğŸ“Š Analyzing all 10 principles...

[chromium] â€º testability-scorer.spec.js:12:1

  âœ“ 1/10 Observability Assessment (5.2s)
    â”œâ”€ Console logs: 12 messages âœ“
    â”œâ”€ Network requests: 8 tracked âœ“
    â”œâ”€ State visibility: Partial âš ï¸
    â”œâ”€ Error reporting: Good âœ“
    â””â”€ Debug mode: Available âœ“
    Score: 76/100 (C)

  âœ— 2/10 Controllability Assessment (3.8s)
    â”œâ”€ Direct API: Not available âœ—
    â”œâ”€ State manipulation: UI-only âœ—
    â”œâ”€ Test data: No injection âœ—
    â”œâ”€ Environment config: Limited âš ï¸
    â””â”€ Feature toggles: None âœ—
    Score: 26/100 (F) âš ï¸

  âœ“ 3/10 Algorithmic Simplicity (4.1s)
    â”œâ”€ Workflow steps: 3-5 average âœ“
    â”œâ”€ Logic branches: Moderate âœ“
    â”œâ”€ Data transforms: Clear âœ“
    â””â”€ Business logic: Transparent âœ“
    Score: 62/100 (D)

  âœ“ 4/10 Algorithmic Transparency (3.5s)
    â”œâ”€ Code readability: Good âœ“
    â”œâ”€ Naming: Descriptive âœ“
    â”œâ”€ Data flow: Visible âœ“
    â””â”€ Calculations: Clear âœ“
    Score: 71/100 (C)

  âœ— 5/10 Explainability (4.2s)
    â”œâ”€ API docs: Minimal âš ï¸
    â”œâ”€ Code comments: Sparse âš ï¸
    â”œâ”€ User guides: Basic âš ï¸
    â””â”€ Error messages: Generic âš ï¸
    Score: 34/100 (F) âš ï¸

  âœ“ 6/10 Similarity to Known Tech (2.8s)
    â”œâ”€ Framework: React (standard) âœ“
    â”œâ”€ Patterns: Common âœ“
    â”œâ”€ Architecture: Familiar âœ“
    â””â”€ Tech stack: Mature âœ“
    Score: 89/100 (B)

  âœ“ 7/10 Algorithmic Stability (3.9s)
    â”œâ”€ API versioning: Present âœ“
    â”œâ”€ Breaking changes: Infrequent âœ“
    â”œâ”€ Regression tests: Partial âš ï¸
    â””â”€ Feature flags: Some âœ“
    Score: 64/100 (D)

  âœ“ 8/10 Unbugginess (4.5s)
    â”œâ”€ Console errors: 2 found âš ï¸
    â”œâ”€ Failed requests: 0 âœ“
    â”œâ”€ UI glitches: Minor âš ï¸
    â””â”€ Test stability: Good âœ“
    Score: 77/100 (C)

  âœ“ 9/10 Smallness (2.1s)
    â”œâ”€ Page size: 850KB âœ“
    â”œâ”€ JS bundle: 420KB âœ“
    â”œâ”€ Dependencies: 23 âœ“
    â””â”€ Complexity: Low âœ“
    Score: 85/100 (B)

  âœ“ 10/10 Decomposability (3.2s)
    â”œâ”€ Components: 18 isolated âœ“
    â”œâ”€ Services: 5 separated âœ“
    â”œâ”€ Test units: Clear âœ“
    â””â”€ Interfaces: Defined âœ“
    Score: 61/100 (D)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ˆ OVERALL TESTABILITY SCORE: 52/100 (F)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ Grade Distribution:
   A (90-100): 0 principles
   B (80-89):  2 principles âœ“ (Similarity, Smallness)
   C (70-79):  3 principles âœ“ (Observability, Transparency, Unbugginess)
   D (60-69):  3 principles âš ï¸ (Simplicity, Stability, Decomposability)
   F (0-59):   2 principles âœ— (Controllability, Explainability)

ğŸš¨ Critical Failures (F grade):
   1. Controllability: 26/100 - Cannot manipulate state directly
   2. Explainability: 34/100 - Poor documentation and error messages

ğŸ“Š Generating reports...
   âœ“ HTML report: tests/reports/testability-report-1732992000.html
   âœ“ JSON report: tests/reports/testability-report-1732992000.json
   âœ“ Text summary: tests/reports/testability-report-1732992000.txt

ğŸ¤– AI-Powered Recommendations (Top 5):

   1. ğŸ”´ CRITICAL: Add Test Mode API
      Principle: Controllability
      Impact: +40 points (26 â†’ 66)
      Effort: Medium (4-8 hours)

      Code Example:
      ```javascript
      // In your app initialization
      if (process.env.NODE_ENV === 'test') {
        window.testAPI = {
          getState: () => store.getState(),
          setState: (state) => store.setState(state),
          clearData: () => store.reset(),
          addUser: (user) => store.dispatch(addUser(user))
        };
      }
      ```

   2. ğŸ”´ HIGH: Improve API Documentation
      Principle: Explainability
      Impact: +25 points (34 â†’ 59)
      Effort: Low (2-4 hours)

      Add JSDoc comments, OpenAPI spec, and README

   3. ğŸŸ¡ MEDIUM: Add State Logging
      Principle: Observability
      Impact: +15 points (76 â†’ 91)
      Effort: Low (1-2 hours)

      Integrate Redux DevTools or custom logger

   4. ğŸŸ¡ MEDIUM: Implement Feature Flags
      Principle: Algorithmic Stability
      Impact: +12 points (64 â†’ 76)
      Effort: Medium (4-6 hours)

   5. ğŸŸ¢ LOW: Add Error Context
      Principle: Explainability
      Impact: +8 points (34 â†’ 42)
      Effort: Low (1-2 hours)

      Include helpful error messages with action steps

ğŸ’° Total Potential Improvement: +100 points â†’ Score: 152/100
ğŸ“Š Realistic Improvement (Top 3): +52 points â†’ Score: 104/100
ğŸ¯ Achievable Target (6-12 hours): Score: 90/100 (A)

âœ… Assessment complete!

ğŸ“„ View full report:
   open tests/reports/testability-report-1732992000.html

ğŸ“ˆ Track improvements:
   node scripts/view-trends.js
```

---

## Example 3: Using with Claude Code (Natural Language)

### Scenario
Ask Claude to analyze testability using natural language.

### Prompt
```
"Analyze the testability of the SauceDemo application and tell me what improvements would have the biggest impact"
```

### Claude's Response
```
I'll analyze the testability of the SauceDemo application using the testability-scorer skill.

[Claude automatically recognizes the testability-scorer skill and uses it]

I've completed a comprehensive testability assessment of SauceDemo. Here are the key findings:

**Overall Score: 52/100 (F)**

**Critical Issues:**

1. **Controllability: 26/100 (F) - CRITICAL**
   - The application lacks direct API access for testing
   - Cannot manipulate state without going through UI
   - No test data injection capabilities

   **Impact of fixing: +40 points**

   Recommendation: Add a test mode API:
   ```javascript
   if (process.env.NODE_ENV === 'test') {
     window.testAPI = {
       login: (username) => { /* direct login */ },
       addToCart: (items) => { /* skip UI navigation */ },
       getCartState: () => { /* read cart directly */ }
     };
   }
   ```

2. **Explainability: 34/100 (F) - HIGH PRIORITY**
   - Minimal API documentation
   - Generic error messages
   - Sparse code comments

   **Impact of fixing: +25 points**

   Recommendation: Add JSDoc comments and improve error messages

**Quick Wins (Highest ROI):**

1. **Add test API** (4-8 hours) â†’ +40 points
2. **Document API endpoints** (2-4 hours) â†’ +25 points
3. **Add state logging** (1-2 hours) â†’ +15 points

**Projected improvement:** From 52/100 (F) to 132/100 â†’ realistically 90/100 (A) with top 3 fixes

Would you like me to:
1. Generate tests focusing on the weak areas?
2. Implement the test API recommendation?
3. Create a detailed improvement roadmap?
```

---

## Example 4: Using with QE Agents

### Scenario
Spawn a QE agent to analyze testability and create an action plan.

### Command (In Claude Code)
```javascript
Task("Analyze and improve testability", `
  Use the testability-scorer skill to:
  1. Run full assessment on https://www.saucedemo.com
  2. Analyze results and identify top 3 critical issues
  3. Store results in memory under aqe/testability/saucedemo
  4. Create a prioritized improvement roadmap with effort estimates
  5. Generate code examples for top recommendation
`, "qe-analyst");
```

### Agent Output
```
ğŸ¤– QE Analyst Agent

Task: Analyze and improve testability

Step 1: Running testability assessment...
âœ“ Completed assessment in 42 seconds

Step 2: Analyzing results...
âœ“ Overall score: 52/100 (F)
âœ“ Identified 2 critical failures
âœ“ Identified 3 high-priority improvements

Step 3: Storing in memory...
âœ“ Stored at aqe/testability/saucedemo/baseline
âœ“ Stored at aqe/testability/saucedemo/latest
âœ“ Stored at aqe/testability/saucedemo/recommendations

Step 4: Creating improvement roadmap...

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ TESTABILITY IMPROVEMENT ROADMAP
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Phase 1 (Week 1): Critical Fixes [+65 points]

  1.1 Add Test Mode API
      Principle: Controllability (26 â†’ 86)
      Effort: 6-8 hours
      Priority: CRITICAL

      Tasks:
      - Create window.testAPI object
      - Add state getters/setters
      - Add data injection methods
      - Document API usage

      Success Criteria:
      - Can set any app state directly
      - Can inject test data via API
      - Controllability score > 70

  1.2 Improve Documentation
      Principle: Explainability (34 â†’ 59)
      Effort: 4-6 hours
      Priority: HIGH

      Tasks:
      - Add JSDoc to all public methods
      - Create API reference doc
      - Document error codes
      - Add usage examples

      Success Criteria:
      - All APIs documented
      - Error messages include help text
      - Explainability score > 50

Phase 2 (Week 2): High-Impact Improvements [+23 points]

  2.1 Add State Logging
      Principle: Observability (76 â†’ 91)
      Effort: 2-3 hours
      Priority: MEDIUM

      Tasks:
      - Add Redux DevTools integration
      - Implement state change logging
      - Add performance monitoring

  2.2 Implement Feature Flags
      Principle: Algorithmic Stability (64 â†’ 76)
      Effort: 4-6 hours
      Priority: MEDIUM

Phase 3 (Week 3): Polish [+12 points]

  3.1 Improve Error Messages
  3.2 Add Integration Tests
  3.3 Document Architecture

Expected Results:
  Current:  52/100 (F)
  Phase 1:  117/100 â†’ capped at 100/100 (A)

  Minimum viable: Phase 1 only (2 weeks)
  Recommended: Phase 1 + Phase 2 (3 weeks)

Step 5: Generating code examples...

Example: Test Mode API Implementation

```javascript
// src/utils/testMode.js
export function initializeTestMode() {
  if (process.env.NODE_ENV !== 'test') {
    return;
  }

  window.testAPI = {
    // Authentication
    login: (username) => {
      const user = getUserByName(username);
      store.dispatch(loginSuccess(user));
      return user;
    },

    logout: () => {
      store.dispatch(logoutUser());
    },

    // State management
    getState: () => {
      return store.getState();
    },

    setState: (state) => {
      store.replaceState(state);
    },

    // Cart operations
    addToCart: (items) => {
      items.forEach(item => {
        store.dispatch(addItem(item));
      });
    },

    clearCart: () => {
      store.dispatch(clearCart());
    },

    getCart: () => {
      return store.getState().cart;
    },

    // Data injection
    setProducts: (products) => {
      store.dispatch(loadProducts(products));
    },

    // Utilities
    reset: () => {
      store.dispatch(resetApp());
      localStorage.clear();
    }
  };

  console.log('âœ“ Test API initialized');
  console.log('Available methods:', Object.keys(window.testAPI));
}
```

Usage in tests:
```javascript
// tests/cart.spec.js
test('Add items to cart via API', async ({ page }) => {
  await page.goto('https://www.saucedemo.com');

  // Use test API instead of UI navigation
  await page.evaluate(() => {
    window.testAPI.login('standard_user');
    window.testAPI.addToCart([
      { id: 1, name: 'Sauce Labs Backpack', price: 29.99 },
      { id: 2, name: 'Sauce Labs Bike Light', price: 9.99 }
    ]);
  });

  const cart = await page.evaluate(() => window.testAPI.getCart());
  expect(cart.items.length).toBe(2);
  expect(cart.total).toBe(39.98);
});
```

âœ… Task complete!

Next steps:
1. Review roadmap and approve phases
2. Implement Phase 1 (critical fixes)
3. Re-run assessment to validate improvements
4. Generate tests using improved testability
```

---

## Example 5: CI/CD Pipeline Integration

### Scenario
Add testability checks to GitHub Actions pipeline.

### Workflow File
```yaml
# .github/workflows/testability.yml
name: Testability Quality Gate

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  testability-check:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Install dependencies
        run: |
          cd .claude/skills/testability-scorer
          chmod +x scripts/*.sh
          ./scripts/install.sh

      - name: Start application
        run: |
          npm install
          npm start &
          npx wait-on http://localhost:3000

      - name: Run testability assessment
        run: |
          cd .claude/skills/testability-scorer
          ./scripts/run-assessment.sh http://localhost:3000 chromium

      - name: Check testability threshold
        run: |
          SCORE=$(jq '.overall' tests/reports/latest.json)
          echo "Testability Score: $SCORE/100"

          if [ "$SCORE" -lt 70 ]; then
            echo "âŒ Testability score $SCORE below threshold 70"
            jq -r '.recommendations[] | "- [\(.severity)] \(.principle): \(.recommendation)"' tests/reports/latest.json
            exit 1
          else
            echo "âœ… Testability score $SCORE meets threshold"
          fi

      - name: Upload HTML report
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: testability-report
          path: tests/reports/testability-report-*.html

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = JSON.parse(fs.readFileSync('tests/reports/latest.json'));

            const grade = report.grade;
            const emoji = grade === 'A' ? 'ğŸŒŸ' : grade === 'B' ? 'âœ…' : grade === 'C' ? 'âš ï¸' : 'âŒ';

            const body = `
            ## ${emoji} Testability Assessment Results

            **Overall Score:** ${report.overall}/100 (${grade})

            ### Principle Scores
            ${Object.entries(report.principles).map(([key, val]) =>
              `- **${key}**: ${val.score}/100 (${val.grade})`
            ).join('\n')}

            ### Top Recommendations
            ${report.recommendations.slice(0, 3).map((rec, i) =>
              `${i+1}. **[${rec.severity.toUpperCase()}]** ${rec.principle}: ${rec.recommendation}`
            ).join('\n')}

            [View Full Report](../artifacts/testability-report)
            `;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
```

### Pipeline Output
```
âœ“ Checkout code
âœ“ Setup Node.js
âœ“ Install dependencies
âœ“ Start application
âœ“ Run testability assessment

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Testability Assessment Complete
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Overall Score: 52/100 (F)

Critical Issues:
- [CRITICAL] Controllability: Add test mode API
- [HIGH] Explainability: Improve documentation

âŒ Testability score 52 below threshold 70

Blocking deployment. Please fix critical issues.

âœ“ Uploaded HTML report to artifacts
âœ“ Posted comment on PR #123
```

---

## Example 6: Tracking Improvements Over Time

### Scenario
Run assessments periodically and track testability improvements.

### Initial Assessment (Week 1)
```bash
./scripts/run-assessment.sh https://myapp.com
# Score: 52/100 (F)
```

### After Implementing Recommendations (Week 2)
```bash
# Implement test API
git checkout -b feature/test-api
# ... make changes ...
git commit -m "feat: add test mode API for better controllability"

# Re-run assessment
./scripts/run-assessment.sh https://myapp.com
# Score: 76/100 (C) +24 points â¬†ï¸
```

### View Improvement Trends
```bash
node scripts/view-trends.js
```

### Output
```
ğŸ“ˆ Testability Improvement Trends

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Assessment History (Last 30 days)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Date                Score  Grade  Change    Trigger
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2025-11-23 10:00    52     F      baseline  Initial assessment
2025-11-25 14:30    62     D      +10 â¬†ï¸    Added state logging
2025-11-27 09:15    76     C      +14 â¬†ï¸    Implemented test API
2025-11-29 16:45    85     B      +9  â¬†ï¸    Improved documentation
2025-11-30 11:20    92     A      +7  â¬†ï¸    Added feature flags

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Principle Improvements
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Principle                Week 1  Week 2  Week 3  Week 4  Change
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Observability            76      82      85      90      +14 â¬†ï¸
Controllability          26      28      85      90      +64 ğŸš€
Algorithmic Simplicity   62      65      68      70      +8  â¬†ï¸
Algorithmic Transparency 71      73      75      78      +7  â¬†ï¸
Explainability           34      38      65      85      +51 ğŸš€
Similarity               89      89      90      92      +3  âœ“
Algorithmic Stability    64      68      72      88      +24 â¬†ï¸
Unbugginess              77      79      82      88      +11 â¬†ï¸
Smallness                85      86      87      88      +3  âœ“
Decomposability          61      64      68      72      +11 â¬†ï¸

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Key Achievements
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ“ Went from F to A grade in 4 weeks
âœ“ Eliminated all F-grade principles
âœ“ Improved by 40 points overall (+77%)
âœ“ Biggest wins:
  â€¢ Controllability: +64 points (26 â†’ 90)
  â€¢ Explainability: +51 points (34 â†’ 85)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Remaining Opportunities
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ To reach 95/100 (A+):
  1. Algorithmic Simplicity: 70 â†’ 85 (+15 points)
     - Reduce workflow complexity
     - Simplify business logic

  2. Decomposability: 72 â†’ 85 (+13 points)
     - Further isolate components
     - Improve service boundaries

Estimated effort: 1-2 weeks
Projected score: 95/100 (A+)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š Chart: https://myapp.com/testability-trends
ğŸ“„ Detailed report: tests/reports/trends-2025-11-30.html
```

---

## Example 7: Multi-User Comparative Analysis

### Scenario
Compare testability across different user types to find role-specific issues.

### Configuration
```javascript
// tests/testability-scorer/config.js
module.exports = {
  baseURL: 'https://www.saucedemo.com',
  userTypes: [
    { username: 'standard_user', password: 'secret_sauce', role: 'standard' },
    { username: 'locked_out_user', password: 'secret_sauce', role: 'locked' },
    { username: 'problem_user', password: 'secret_sauce', role: 'problem' },
    { username: 'performance_glitch_user', password: 'secret_sauce', role: 'performance' }
  ]
};
```

### Run Comparative Analysis
```bash
npx playwright test tests/testability-scorer/multi-user-comparison.spec.js
```

### Output
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Multi-User Testability Comparison
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

User Type          Overall  Observ  Control  Simple  Explain
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
standard_user      52 (F)   76 (C)  26 (F)   62 (D)  34 (F)
locked_out_user    45 (F)   68 (D)  20 (F)   58 (F)  30 (F)  âš ï¸
problem_user       38 (F)   52 (F)  18 (F)   45 (F)  25 (F)  âš ï¸
performance_user   41 (F)   60 (D)  22 (F)   51 (F)  28 (F)  âš ï¸

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” Key Findings:

1. Standard User: Best testability
   - Most reliable user type for testing
   - Highest scores across all principles

2. Problem User: Worst testability (-14 points)
   - Observability issues (cart display bugs)
   - Simplicity problems (unexpected behavior)
   - Recommend: Fix user-specific bugs first

3. All Users: Controllability Critical
   - All users score F in controllability
   - Universal issue, not user-specific
   - Priority: Implement test API

4. Performance User: Timing Issues
   - Observability affected by delays
   - Consider: Add wait strategies for tests

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Recommendations:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ Universal Improvements (All Users):
   â€¢ Add test API â†’ +40 points across all users
   â€¢ Improve docs â†’ +25 points across all users

ğŸ¯ User-Specific Fixes:
   â€¢ Problem user: Fix cart display bug â†’ +20 points
   â€¢ Performance user: Optimize load times â†’ +15 points
   â€¢ Locked out user: Better error messaging â†’ +10 points

Expected Impact:
   Standard user: 52 â†’ 92 (+40 points)
   Problem user:  38 â†’ 78 (+40 points)
```

---

These examples demonstrate the skill's versatility across different use cases - from quick CLI checks to complex CI/CD integration and AI agent coordination. The skill adapts to your workflow whether you're doing manual testing, automated assessments, or building comprehensive quality gates.

Would you like me to show more examples for specific scenarios?
